global:
  namespace: ollyscale
replicaCount: 1
image:
  pullPolicy: Always
  pullSecrets: []
commonLabels: {}
commonAnnotations: {}

# OpenTelemetry collectors and instrumentation are now in the separate ollyscale-otel chart
# Deploy ollyscale-otel chart to otel-system namespace before deploying this chart

# Configuration for referencing instrumentation from ollyscale-otel chart
instrumentation:
  # Whether to enable auto-instrumentation annotations on ollyscale pods
  enabled: true
  # Enable self-observability (instrument ollyscale's own services)
  selfObservability: true
  # Name of the Instrumentation CR in otel-system namespace
  name: ollyscale-instrumentation

api:
  replicaCount: 1
  # CNPG secret name to mount for database connection
  # The secret should contain 'uri' and 'dbname' fields
  databaseSecretName: ollyscale-db-app
  image:
    repository: docker-registry.registry.svc.cluster.local:5000/ollyscale/api
    tag: 0.0.0-dev.1770226204
    pullPolicy: ''
  serviceAccount:
    create: true
    name: ''
    annotations: {}
  podAnnotations: {}
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: false
  service:
    type: ClusterIP
    port: 8000
    targetPort: 8000
    nodePort: null
    annotations: {}
  httpRoute:
    enabled: false
  resources:
    limits:
      memory: 1Gi
    requests:
      cpu: 200m
      memory: 256Mi
  livenessProbe:
    httpGet:
      path: /health/
      port: 8000
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    httpGet:
      path: /health/
      port: 8000
    initialDelaySeconds: 10
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3
  env:
    - name: DEPLOYMENT_ENV
      value: kubernetes
    - name: OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED
      value: 'true'
webui:
  replicaCount: 1
  image:
    repository: ghcr.io/ryanfaircloth/ollyscale/web-ui
    tag: 0.0.0-dev.1770226204
    pullPolicy: ''
  serviceAccount:
    create: true
    name: ''
    annotations: {}
  podAnnotations: {}
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 101
    fsGroup: 101
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: false
  service:
    type: ClusterIP
    port: 8080
    targetPort: 8080
    nodePort: null
    annotations: {}
  httpRoute:
    enabled: true
    annotations: {}
    parentRefs:
      - name: management-gateway
        namespace: envoy-gateway-system
    hosts:
      - host: ollyscale.local.gd
        path: /
        pathType: PathPrefix
  resources:
    limits:
      memory: 256Mi
    requests:
      cpu: 50m
      memory: 64Mi
  livenessProbe:
    httpGet:
      path: /
      port: 8080
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 3
    failureThreshold: 3
  readinessProbe:
    httpGet:
      path: /
      port: 8080
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 2
    failureThreshold: 3
  env: []
  extraEnv: {}
  volumeMounts: []
  volumes: []
  nodeSelector: {}
  tolerations: []
  affinity: {}
opampServer:
  replicaCount: 1
  image:
    repository: ghcr.io/ryanfaircloth/ollyscale/opamp-server
    tag: 0.0.0-dev.1770226204
    pullPolicy: ''
  serviceAccount:
    create: true
    name: ''
    annotations: {}
  podAnnotations: {}
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: false
  service:
    type: ClusterIP
    websocketPort: 4320
    httpPort: 4321
    annotations: {}
  resources:
    limits: {}
    requests:
      cpu: 50m
      memory: 128Mi
  livenessProbe:
    httpGet:
      path: /health
      port: 4321
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    httpGet:
      path: /health
      port: 4321
    initialDelaySeconds: 10
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3
  env:
    - name: OPAMP_PORT
      value: '4320'
    - name: HTTP_PORT
      value: '4321'
    - name: COLLECTOR_CONFIG_PATH
      value: /etc/otel-collector-config.yaml
  extraEnv: {}
  volumeMounts: []
  volumes: []
  nodeSelector: {}
  tolerations: []
  affinity: {}
otlpReceiver:
  replicaCount: 1
  # CNPG secret name to mount for database connection
  # The secret should contain 'uri' and 'dbname' fields
  databaseSecretName: ollyscale-db-app
  image:
    repository: docker-registry.registry.svc.cluster.local:5000/ollyscale/api
    tag: 0.2.0
    pullPolicy: ''
  serviceAccount:
    create: true
    name: ''
    annotations: {}
  podAnnotations: {}
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: false
  service:
    type: ClusterIP
    port: 4343
    targetPort: 4343
    annotations: {}
  resources:
    limits:
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 256Mi
  livenessProbe:
    tcpSocket:
      port: 4343
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    tcpSocket:
      port: 4343
    initialDelaySeconds: 10
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3
  env:
    - name: OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED
      value: 'true'
  extraEnv: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}

# PostgreSQL is now deployed separately via ollyscale-postgres chart
# Configure the database secret name to connect to external postgres
# api:
#   databaseSecretName: ollyscale-postgres-app
# otlpReceiver:
#   databaseSecretName: ollyscale-postgres-app

migration:
  resources:
    limits:
      memory: 256Mi
    requests:
      cpu: 50m
      memory: 128Mi
  nodeSelector: {}
  tolerations: []
partitionMaintenance:
  enabled: true
  schedule: 0 2 * * *
  daysAhead: 7
  resources:
    limits:
      memory: 256Mi
    requests:
      cpu: 50m
      memory: 128Mi
  nodeSelector: {}
  tolerations: []
migrations:
  image:
    tag: 0.0.0-dev.1770226204
